import os
import logging
from telegram import Update, InlineKeyboardMarkup, InlineKeyboardButton
from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, CallbackQueryHandler, filters
from dotenv import load_dotenv
from duckduckgo_search import DDGS
from PIL import Image
import pytesseract
from io import BytesIO
import speech_recognition as sr
from pydub import AudioSegment
import requests

load_dotenv()

TOKEN = os.getenv("TOKEN")
OWNER_ID = int(os.getenv("OWNER_ID"))
KASPI_NAME = os.getenv("KASPI_NAME")

logging.basicConfig(level=logging.INFO)

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–ø–ª–∞—Ç—ã –ø–æ —á–µ–∫—É
async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    photo = update.message.photo[-1]
    file = await context.bot.get_file(photo.file_id)
    img_bytes = await file.download_as_bytearray()
    image = Image.open(BytesIO(img_bytes))
    text = pytesseract.image_to_string(image)

    if KASPI_NAME.lower() in text.lower():
        await update.message.reply_text("‚úÖ –û–ø–ª–∞—Ç–∞ –Ω–∞–π–¥–µ–Ω–∞. –î–æ—Å—Ç—É–ø –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω –Ω–∞ 48 —á–∞—Å–æ–≤.")
        # –∑–¥–µ—Å—å –º–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–æ—Å—Ç—É–ø –≤ –±–∞–∑—É
    else:
        await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å –æ–ø–ª–∞—Ç—É. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —á–µ–∫ —á–∏—Ç–∞–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ –≤–∏–¥–µ —Ñ–æ—Ç–æ.")

# –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    voice = update.message.voice
    file = await context.bot.get_file(voice.file_id)
    voice_ogg = BytesIO()
    await file.download_to_memory(out=voice_ogg)
    voice_ogg.seek(0)

    ogg_path = "voice.ogg"
    wav_path = "voice.wav"

    with open(ogg_path, "wb") as f:
        f.write(voice_ogg.read())

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è ogg –≤ wav
    audio = AudioSegment.from_ogg(ogg_path)
    audio.export(wav_path, format="wav")

    recognizer = sr.Recognizer()
    with sr.AudioFile(wav_path) as source:
        audio_data = recognizer.record(source)
        try:
            text = recognizer.recognize_google(audio_data, language="ru-RU")
            await update.message.reply_text(f"–í—ã —Å–∫–∞–∑–∞–ª–∏: {text}")
            await search_places(update, context, text)
        except sr.UnknownValueError:
            await update.message.reply_text("üòï –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å.")
        except Exception as e:
            await update.message.reply_text(f"–û—à–∏–±–∫–∞: {e}")

# –ü–æ–∏—Å–∫ –∑–∞–≤–µ–¥–µ–Ω–∏–π
async def search_places(update: Update, context: ContextTypes.DEFAULT_TYPE, query=None):
    if not query:
        query = update.message.text
    await update.message.reply_text("üîé –ò—â—É –∑–∞–≤–µ–¥–µ–Ω–∏—è –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É...")

    results = []
    with DDGS() as ddgs:
        for r in ddgs.text(f"{query} site:2gis.kz", region="kz-ru", max_results=5):
            results.append(f"{r['title']}\n{r['href']}\n")

    if results:
        await update.message.reply_text("\n\n".join(results))
    else:
        await update.message.reply_text("üòî –ù–µ –Ω–∞—à—ë–ª –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∑–∞–≤–µ–¥–µ–Ω–∏–π. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π –∑–∞–ø—Ä–æ—Å.")

# –ö–Ω–æ–ø–∫–∏
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    buttons = [
        [InlineKeyboardButton("üéôÔ∏è –ì–æ–ª–æ—Å–æ–º", callback_data="voice")],
        [InlineKeyboardButton("üì∏ –§–æ—Ç–æ —á–µ–∫–∞", callback_data="check")]
    ]
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –ø–æ–º–æ–≥—É —Ç–µ–±–µ –Ω–∞–π—Ç–∏ –ª—É—á—à–∏–µ –º–µ—Å—Ç–∞ –¥–ª—è –æ—Ç–¥—ã—Ö–∞ –∏ –ø—Ä–æ–≤–µ—Ä—é –æ–ø–ª–∞—Ç—É.\n\n–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏, –∫—É–¥–∞ —Ö–æ—á–µ—à—å –ø–æ–π—Ç–∏, –æ—Ç–ø—Ä–∞–≤—å –≥–æ–ª–æ—Å –∏–ª–∏ —Ñ–æ—Ç–æ —á–µ–∫–∞.",
        reply_markup=InlineKeyboardMarkup(buttons)
    )

async def button_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    if query.data == "voice":
        await query.edit_message_text("üé§ –û—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
    elif query.data == "check":
        await query.edit_message_text("üì∏ –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ Kaspi-—á–µ–∫–∞.")

def main():
    app = ApplicationBuilder().token(TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CallbackQueryHandler(button_handler))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, search_places))
    app.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))

    app.run_polling()

if __name__ == "__main__":
    main()
